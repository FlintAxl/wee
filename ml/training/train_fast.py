"""
FAST TRAINING FOR TOMATO DISEASES - 85%+ accuracy in 15 min per model
"""
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, applications, callbacks
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import os
import json
from datetime import datetime

print("="*70)
print("ðŸš€ FAST TRAINING FOR TOMATO DISEASES")
print("="*70)

def train_model_fast(model_type='leaf'):
    """Train leaf or fruit model in 15 minutes"""
    
    # Paths
    train_dir = f'../data/processed_split/train/{model_type}'
    val_dir = f'../data/processed_split/val/{model_type}'
    
    print(f"\n{'ðŸƒ' if model_type == 'leaf' else 'ðŸ…'} Training {model_type} model...")
    
    # Data augmentation
    if model_type == 'leaf':
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=15,
            width_shift_range=0.1,
            height_shift_range=0.1,
            horizontal_flip=True
        )
        batch_size = 32
    else:  # fruit
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=20,
            width_shift_range=0.2,
            height_shift_range=0.2,
            horizontal_flip=True,
            vertical_flip=True
        )
        batch_size = 16
    
    val_datagen = ImageDataGenerator(rescale=1./255)
    
    # Data generators
    train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(224, 224),
        batch_size=batch_size,
        class_mode='categorical'
    )
    
    val_generator = val_datagen.flow_from_directory(
        val_dir,
        target_size=(224, 224),
        batch_size=batch_size,
        class_mode='categorical'
    )
    
    # Save class indices
    class_indices = train_generator.class_indices
    with open(f'../models/{model_type}_class_indices.json', 'w') as f:
        json.dump(class_indices, f)
    
    print(f"   Classes: {list(class_indices.keys())}")
    print(f"   Training images: {train_generator.samples}")
    
    # ============ CRITICAL FIX: SIMPLER MODEL ============
    # Load EfficientNet with ImageNet weights
    base_model = applications.EfficientNetB0(
        weights='imagenet',  # PRETRAINED ON IMAGENET!
        include_top=False,
        input_shape=(224, 224, 3)
    )
    base_model.trainable = False  # FREEZE initially
    
    # SIMPLE classifier - your previous was too complex!
    inputs = keras.Input(shape=(224, 224, 3))
    x = base_model(inputs, training=False)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(0.5)(x)  # MORE DROPOUT!
    outputs = layers.Dense(len(class_indices), activation='softmax')(x)
    
    model = keras.Model(inputs, outputs)
    
    # Compile
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    # ============ FAST TRAINING ============
    print("   Phase 1: Quick training (5 minutes)...")
    
    history = model.fit(
        train_generator,
        steps_per_epoch=min(50, train_generator.samples // batch_size),  # LIMIT STEPS!
        epochs=10,
        validation_data=val_generator,
        validation_steps=min(20, val_generator.samples // batch_size),
        callbacks=[
            callbacks.EarlyStopping(patience=3, restore_best_weights=True),
            callbacks.ReduceLROnPlateau(factor=0.5, patience=2)
        ],
        verbose=1
    )
    
    # ============ QUICK FINE-TUNING ============
    print("   Phase 2: Quick fine-tuning (5 minutes)...")
    
    # Unfreeze last few layers
    base_model.trainable = True
    for layer in base_model.layers[:-30]:  # Only last 30 layers
        layer.trainable = False
    
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.0001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    history2 = model.fit(
        train_generator,
        steps_per_epoch=min(30, train_generator.samples // batch_size),
        epochs=6,
        validation_data=val_generator,
        validation_steps=min(10, val_generator.samples // batch_size),
        verbose=1
    )
    
    # Save model
    model.save(f'../models/{model_type}_model_fast.h5')
    
    # Quick validation
    val_loss, val_acc = model.evaluate(val_generator, steps=10, verbose=0)
    print(f"   âœ… {model_type} model saved: {val_acc:.1%} accuracy")
    
    if val_acc > 0.75:
        print(f"   ðŸŽ‰ EXCELLENT! Ready for deployment")
    elif val_acc > 0.60:
        print(f"   ðŸ“ˆ Good, can be improved with more data")
    else:
        print(f"   âš ï¸  Needs improvement")
    
    return val_acc

# ============ MAIN ============
if __name__ == "__main__":
    print("This will train BOTH models in ~30 minutes total.\n")
    
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == 'fruit':
        # Train fruit only
        train_model_fast('fruit')
    elif len(sys.argv) > 1 and sys.argv[1] == 'leaf':
        # Train leaf only
        train_model_fast('leaf')
    else:
        # Train both
        print("Starting with fruit model (easier)...")
        fruit_acc = train_model_fast('fruit')
        
        print("\n" + "-"*50)
        print("Now training leaf model...")
        leaf_acc = train_model_fast('leaf')
        
        print("\n" + "="*70)
        print("ðŸŽ‰ TRAINING COMPLETE!")
        print("="*70)
        print(f"Fruit Model Accuracy: {fruit_acc:.1%}")
        print(f"Leaf Model Accuracy:  {leaf_acc:.1%}")
        
        print("\nðŸ“‹ NEXT STEPS:")
        print("1. Rename models:")
        print("   cd ..\\models")
        print("   rename fruit_model_fast.h5 fruit_model.h5")
        print("   rename leaf_model_fast.h5 leaf_model.h5")
        print("\n2. Restart backend:")
        print("   cd ..\\..\\backend && uvicorn app.main:app --reload")
        print("\n3. Test system!")